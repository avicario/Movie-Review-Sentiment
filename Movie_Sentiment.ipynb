{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn import tree\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.classify import MaxentClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(directory):\n",
    "    movie_train = load_files(directory, shuffle=True)\n",
    "    # No IDF\n",
    "    movie_vec = CountVectorizer(binary=True,tokenizer=nltk.word_tokenize)     \n",
    "    movie_counts = movie_vec.fit_transform(movie_train.data[:2000])\n",
    "\n",
    "    tf_transformer = TfidfTransformer(use_idf=False)\n",
    "    movie_tf = tf_transformer.fit_transform(movie_counts)\n",
    "\n",
    "    docs_trn, docs_tst, y_trn, y_tst = train_test_split(movie_tf, movie_train.target)\n",
    "    return docs_trn, docs_tst, y_trn, y_tst\n",
    "\n",
    "# Stop word removed\n",
    "def train_test_2(directory):\n",
    "    movie_train = load_files(directory, shuffle=True)\n",
    "    # No IDF\n",
    "    movie_vec = CountVectorizer(binary=True,tokenizer=nltk.word_tokenize,stop_words=\"english\")     \n",
    "    movie_counts = movie_vec.fit_transform(movie_train.data[:2000])\n",
    "\n",
    "    tf_transformer = TfidfTransformer(use_idf=False)\n",
    "    movie_tf = tf_transformer.fit_transform(movie_counts)\n",
    "\n",
    "    docs_trn, docs_tst, y_trn, y_tst = train_test_split(movie_tf, movie_train.target)\n",
    "    return docs_trn, docs_tst, y_trn, y_tst\n",
    "    \n",
    "    \n",
    "# Including Stop words + *IDF\n",
    "def train_test_3(directory):\n",
    "    movie_train = load_files(directory, shuffle=True)\n",
    "    # No IDF\n",
    "    movie_vec = CountVectorizer(binary=True,tokenizer=nltk.word_tokenize)     \n",
    "    movie_counts = movie_vec.fit_transform(movie_train.data[:2000])\n",
    "\n",
    "    tf_transformer = TfidfTransformer(use_idf=True)\n",
    "    movie_tf = tf_transformer.fit_transform(movie_counts)\n",
    "\n",
    "    docs_trn, docs_tst, y_trn, y_tst = train_test_split(movie_tf, movie_train.target)\n",
    "    return docs_trn, docs_tst, y_trn, y_tst\n",
    "    \n",
    "# removing Stop words + *IDF\n",
    "def train_test_4(directory):\n",
    "    movie_train = load_files(directory, shuffle=True)\n",
    "    # No IDF\n",
    "    movie_vec = CountVectorizer(binary=True,tokenizer=nltk.word_tokenize,stop_words=\"english\")     \n",
    "    movie_counts = movie_vec.fit_transform(movie_train.data[:2000])\n",
    "\n",
    "    tf_transformer = TfidfTransformer(use_idf=True)\n",
    "    movie_tf = tf_transformer.fit_transform(movie_counts)\n",
    "\n",
    "    docs_trn, docs_tst, y_trn, y_tst = train_test_split(movie_tf, movie_train.target)\n",
    "    return docs_trn, docs_tst, y_trn, y_tst\n",
    "    \n",
    "def results(train_doc,train_target,test_doc,test_target):\n",
    "    # naive bayes\n",
    "    clfb = MultinomialNB().fit(train_doc, train_target)\n",
    "    y_pred = clfb.predict(test_doc)\n",
    "    # Decision Tree\n",
    "    clf2 = tree.DecisionTreeClassifier().fit(docs_train, y_train)\n",
    "    y_pred2 = clf2.predict(docs_test)\n",
    "    # Max Entropy\n",
    "    clf3=LogisticRegression().fit(docs_train, y_train)\n",
    "    y_pred3 = clf3.predict(docs_test)\n",
    "\n",
    "    print(\"Naïve Bayes\")\n",
    "    print(\"Accuracy: {}\".format(sklearn.metrics.accuracy_score(test_target, y_pred)))\n",
    "    print(\"F1: {}\".format(round(sklearn.metrics.f1_score(test_target, y_pred),3)))\n",
    "    print(\"\\n\")\n",
    "    print(\"Decision Tree\")\n",
    "    print(\"Accuracy: {}\".format(sklearn.metrics.accuracy_score(test_target, y_pred2)))\n",
    "    print(\"F1: {}\".format(round(sklearn.metrics.f1_score(test_target, y_pred2),3)))\n",
    "    print(\"\\n\")\n",
    "    print(\"Logit (MaxEnt)\")\n",
    "    print(\"Accuracy: {}\".format(sklearn.metrics.accuracy_score(test_target, y_pred3)))\n",
    "    print(\"F1: {}\".format(round(sklearn.metrics.f1_score(test_target, y_pred3),3)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including stopwords, no *IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyvicario/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "docs_train, docs_test, y_train, y_test= train_test(\"/Users/anthonyvicario/movie_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes\n",
      "Accuracy: 0.83\n",
      "F1: 0.832\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Accuracy: 0.632\n",
      "F1: 0.621\n",
      "\n",
      "\n",
      "Logit (MaxEnt)\n",
      "Accuracy: 0.808\n",
      "F1: 0.803\n"
     ]
    }
   ],
   "source": [
    "results(docs_train, y_train, docs_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stopwords, no *IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyvicario/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "docs_train, docs_test, y_train, y_test= train_test_2(\"/Users/anthonyvicario/movie_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes\n",
      "Accuracy: 0.854\n",
      "F1: 0.858\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Accuracy: 0.604\n",
      "F1: 0.594\n",
      "\n",
      "\n",
      "Logit (MaxEnt)\n",
      "Accuracy: 0.85\n",
      "F1: 0.851\n"
     ]
    }
   ],
   "source": [
    "results(docs_train, y_train, docs_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including Stop words + *IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyvicario/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "docs_train, docs_test, y_train, y_test= train_test_3(\"/Users/anthonyvicario/movie_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes\n",
      "Accuracy: 0.806\n",
      "F1: 0.791\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Accuracy: 0.596\n",
      "F1: 0.604\n",
      "\n",
      "\n",
      "Logit (MaxEnt)\n",
      "Accuracy: 0.862\n",
      "F1: 0.868\n"
     ]
    }
   ],
   "source": [
    "results(docs_train, y_train, docs_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stop words + *IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyvicario/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "docs_train, docs_test, y_train, y_test= train_test_3(\"/Users/anthonyvicario/movie_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes\n",
      "Accuracy: 0.8\n",
      "F1: 0.815\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Accuracy: 0.596\n",
      "F1: 0.591\n",
      "\n",
      "\n",
      "Logit (MaxEnt)\n",
      "Accuracy: 0.872\n",
      "F1: 0.866\n"
     ]
    }
   ],
   "source": [
    "results(docs_train, y_train, docs_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
